\documentclass {article} 

\usepackage{lmodern}
\usepackage [spanish] {babel} 
\usepackage [T1]{fontenc}
\usepackage [latin1]{inputenc}
\usepackage{amsthm} % para poder usar newtheorem
\usepackage{cancel} %Para poder hacer el simbolo "no es consecuencia semántica" etc.
\usepackage{graphicx} 
\usepackage{amsmath} %para poder usar mathbb
\usepackage{amsfonts} %sigo intentando usar mathbb
\usepackage{amssymb} %therefore
\usepackage{ mathabx } %comillas
\usepackage{ verbatim } 
\theoremstyle{remark}
\newtheorem{thm}{Teorema}
\newtheorem{lem}{Lema}[section]
\newtheorem{cor}{Corolario}[section]
\newtheorem{deff}{Definición}[section]
\newtheorem{obs}{Observación}[section]
\newtheorem{ej}{Ejercicio}[section]
\newtheorem{ex}{Ejemplo}[section]
\newtheorem{alg}{Algoritmo}[section]
\usepackage[latin1]{inputenc} 
\usepackage{listings}
\usepackage{verbatim}
\usepackage{hyperref}
\usepackage{proof}
\usepackage{anysize}
\marginsize{3cm}{3cm}{3cm}{3cm}
\usepackage{tikz}
\usepackage{subfig}



\begin{document} 



\begin{titlepage}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

\center % Center everything on the page
 
%----------------------------------------------------------------------------------------
%	HEADING SECTIONS
%----------------------------------------------------------------------------------------

\textsc{\Large Facultad de Ciencias Exactas, Ingeniería y Agrimensura}\\[1.5cm] % Name of your university/college

\textsc{ \Large Introducción a la Inteligencia Artificial}\\[0.5cm] % Minor heading such as course title

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\HRule \\[0.4cm]
{ \huge \bfseries TRABAJO PRÁCTICO 2}\\[0.4cm] % Title of your document
\HRule \\[1.5cm]
 
%----------------------------------------------------------------------------------------
%	AUTHOR SECTION
%----------------------------------------------------------------------------------------

%\begin{minipage}{0.4\textwidth}
%\begin{flushleft} \large
%\emph{Autor:}\\
%Rodríguez Jeremías % Your name
%\end{flushleft}
%\end{minipage}

%\begin{minipage}{0.4\textwidth}
%\begin{flushright} \large
%\emph{Profesor:} \\
%Mauro Jaskelioff % Supervisor's Name
%\end{flushright}
%\end{minipage}\\[4cm]

% If you don't want a supervisor, uncomment the two lines below and remove the section above
\Large \emph{Alumno: Rodríguez Jeremías}\\


%----------------------------------------------------------------------------------------
%	DATE SECTION
%----------------------------------------------------------------------------------------

{\large \today}\\[3cm] % Date, change the \today to a set date if you want to be precise

%----------------------------------------------------------------------------------------
%	LOGO SECTION
%----------------------------------------------------------------------------------------

%\includegraphics{Logo}\\[1cm] % Include a department/university logo - this will require the graphicx package
 
%----------------------------------------------------------------------------------------

\vfill % Fill the rest of the page with whitespace

\end{titlepage}

\section{Ejercicio A: Mínimos locales}
\par Usamos redes neuronales para aprender a clasificar si un punto en el plano está dentro de dos elipses determinadas. El conjunto de test es el siguiente: \\


\begin{center}

\includegraphics[width=1\textwidth]{A0.pdf}

\end{center}


\par En este ejercicio analicé cómo varía el error porcentual obtenido por la red neuronal final que retorna el algoritmo $bp$ en función de los parámetros \textbf{momentum} y \textbf{learning rate} en el conjunto de training.
\par Usé 3 valores para cada uno de estos parámetros, y para cada una de las 9 combinaciones ejecuté el algorimo $bp$ 20 veces. De las 20 ejecuciones, se puede ver en la siguiente tabla la mediana de ellos (en \%):


\begin{center}
\begin{tabular}[t]{| l|c |c |c|}
\hline
 & m=0 & m=0.5 & m=0.9 \\
\hline
lr=0.001& 19.700000 & 19.400001 & 17.950000 \\
\hline
lr=0.01& 16.550000 & 6.450000 & 14.700000 \\
\hline
lr=0.1& 6.700000 & 15.200000 & 19.550000 \\
\hline
\end{tabular}
\end{center}

\par Como vemos, el menor error se dió para $lr=0.01$ y $m=0.5$. La siguiente gráfica muestra los errores de test, validación y training y su evolución a través de las iteraciones del algoritmo en la ejecución que obtuvo como resultado el valor óptimo ($6.45\%$).


\begin{center}

\includegraphics[width=1\textwidth]{A1.pdf}

\end{center}

\par Para comparar, veamos la gráfica de la ejecución que obtuvo como valor 17.95\% en la tabla:

\begin{center}

\includegraphics[width=1\textwidth]{A2.pdf}

\end{center}

\par En primer lugar puedo observar que el error varía mucho para distintas combinaciones de learning rate y momentos. Por lo tanto, es crucial elegir valores adecuados. Este problema en particular (dos elipses) obtuvo los mejores resultados con LR=0.01 y M=0.5. Esto parece indicar que valores muy similares a estos producen resultados óptimos para este problema en concreto. 

\newpage

\section{Ejercicio B}
\par En este ejercicio analizaremos el error porcentual en el problema de clasificación de las espirales anidades, de acuerdo a la cantidad de neuronas en la capa intermedia. El procedimiento fue análogo al ejercicio anterior, realizando 7 entrenamientos para cada configuración de neuronas en la capa intermedia y seleccionando la mediana. La tabla obtenida fue la siguiente:

\begin{center}
\begin{tabular}[t]{| l|c |}
\hline
n & Error \% \\
\hline
2 & 39.649999 \\
\hline
5 & 36.100000\\
\hline
10 & 23.000000 \\
\hline
20 & 9.800000 \\
\hline
40 & 8.450000 \\
\hline
\end{tabular}
\end{center}

Y las gráficas de las predicciones de las redes de donde provienen esos porcentajes son:

\begin{center}

\begin{figure}[h]
\centering
\begin{minipage}{7cm}
\includegraphics[width=7cm]{B2.pdf}

\label{fig:2figsB}
\end{minipage}
\begin{minipage}{7cm}
\includegraphics[width=7cm]{B5.pdf}

\label{fig:2figsB}
\end{minipage}
\begin{minipage}{7cm}
\includegraphics[width=7cm]{B10.pdf}

\label{fig:3figsB}
\end{minipage}
\begin{minipage}{7cm}
\includegraphics[width=7cm]{B20.pdf}

\label{fig:3figsB}
\end{minipage}

\end{figure}
\end{center}


\begin{center}
\begin{figure}[h]
\centering
\includegraphics[width=0.70\textwidth]{B40.pdf}
\end{figure}
\end{center}

Como podemos observar, cuando aumenta la cantidad de neuronas en la capa intermedia la red clasifica cada vez mejor los puntos en el conjunto de test. La diferencia se hace mucho más notoria al principio. Si siguieramos agregando neuronas el error seguiría bajado, aunque correríamos el riesgo de aprender ruido.


\newpage

\section{Ejercicio C}
\par Este es el primer problema de regresión al cuál nos enfrentamos. En este ejercicio, vamos a ir modificando la proporción de los datos que se utilizan para training-validación, y viendo como responde el error a estos cambios. Se toman 100 elementos del conjunto de training a repartir entre validación y entrenamiento de la red.
\par Se utilizan tres proporciones: 95-5, 75-25 y 50-50 (training - validación). Para cada una de estas proporciones, se realizaron 20 entrenamientos y se eligieron los entrenamientos cuyo error era la mediana del grupo para realizar las siguientes gráficas:

\begin{center}

\begin{figure}[h]
\centering
\begin{minipage}{7cm}
\includegraphics[width=7cm]{C1.pdf}

\label{fig:2figsB}
\end{minipage}
\begin{minipage}{7cm}
\includegraphics[width=7cm]{C2.pdf}

\label{fig:2figsB}
\end{minipage}
\begin{minipage}{7cm}
\includegraphics[width=7cm]{C3.pdf}

\label{fig:3figsB}
\end{minipage}


\end{figure}
\end{center}

\par Como ya hemos estudiado, la función del conjunto de validación es estimar la curva de test para evitar sobreajuste. En estas tres gráficas podemos ver claramente como la curva verde (validación) estima mejor la curva roja (test) a medida que el conjunto de validación es mayor. 
\par La siguiente tabla muestra la mediana de los errores:

\begin{center}
\begin{tabular}[t]{| l|c |}
\hline
\% valid & Error \% \\
\hline
5 & 0.087282 \\
\hline
25 & 0.088184\\
\hline
50 & 0.112632 \\
\hline
\end{tabular}
\end{center}


Lo cual parece indicar que, para este ejemplo en particular, tener datos de validación para evitar el sobreajuste no ayuda demasiado porque quedan muy pocos puntos en training. Si bien se estima la curva de test mejor, el error es muy alto.

 \newpage 
\section{Ejercicio D}
\par Realicé las modificaciones en el algoritmo $bp$ indicadas en el libro (ver código, hay comentarios aclarando dónde modifiqué) para implementar weight decay.
\par Luego, al igual que los ejercicios anteriores, entrené redes neuronales variando un parámetro $\gamma$ para resolver el progrema de regresión Sunspots. En este caso, el parámetro del weight decay varió entre $10^0$ y $10^{-8}$. Recordemos que no se usaron datos de validación.
\par Se entrenaron 20 redes para cada valor de $\gamma$ y elegí la mediana como red representativa. La siguiente tabla muestra los resultados:


\begin{center}
\begin{tabular}[t]{| l |c |}
\hline
$\gamma$ & Error \\
\hline
0.0000001 & 0.006335 \\
\hline
0.000001 & 0.006058\\
\hline
0.00001 & 0.005127\\
\hline
0.0001 & 0.006636\\
\hline
0.001 & 0.013038\\
\hline
0.01 & 0.035926\\
\hline
0.1 & 0.040284\\
\hline
1 & 0.055126\\
\hline
\end{tabular}
\end{center}

Como vemos, este problema se beneficia más de un valor $\gamma = 0.00001$ pues minimiza el error y evita el sobreajuste: vemos que la curva de error de test y la curva de error de training se comportan de forma similar, además la curva de test se mantiene no creciente.

\begin{center}
\begin{figure}[h]
\centering
\includegraphics[width=0.70\textwidth]{D1.pdf}
\end{figure}
\end{center}

Veamos esta misma gráfica comparada con otro valor de $\gamma$ (izquierda), y el comportamiento de los valores de weight decay comparando ambos valores de gamma:

\begin{center}

\begin{figure}[h]
\centering
\begin{minipage}{7cm}
\includegraphics[width=7cm]{D2.pdf}

\label{fig:2figsB}
\end{minipage}
\begin{minipage}{7cm}
\includegraphics[width=7cm]{D3.pdf}

\label{fig:2figsB}
\end{minipage}
\end{figure}
\end{center}

Vemos que con el otro valor de gamma la red sobreajusta. En general, viendo todas las gráficas, puedo conlcuir que usando valores de gamma muy pequeños la red sobreajusta y el errore de test crece rápidamente para este problema (además no tenemos conjunto de validación).
Sin embargo, usar gamma muy grandes conducen a redes muy rígidas donde el error de training es mayor al error en test.\\

OBS! El rótulo correcto del eje y del segundo gráfico es decay, no MSE. Esta gráfica muestra el término agregado al error ANTES de multiplicarlo por $\gamma$.\\

El código está en la carpeta D y las modificaciónes estan precedidas por un comentario que dice AGREGADO.


\newpage

\section{Ejercicio E}
\par Repetiré el ejercicio de la práctica anterior donde se comparaba el problema paralelo con el diagonal variando la cantidad de dimensiones. Para cada número de dimensiones de los problemas diagonal y paralelo, entrenaré 20 redes neuronales y elegiré la correspondiente a la mediana del error discreto como representante.\\
\par Además compararé los resultados obtenidos en este trabajo con los obtenidos en el anterior usando árboles.

\begin{center}
\begin{figure}[h]
\centering
\includegraphics[width=0.70\textwidth]{E.pdf}
\end{figure}
\end{center}

Vemos que para abordar el problema diagonal es mucho mejor utilizar una red neuronal, ya que como vimos antes los árboles de decisión requieren mucho trabajo y árboles muy grandes para representar este problema. Por otro lado, para abordar el problema paralelo es un poco mejor usar árboles, ya que el problema puede ser simplemente expersado por un árbol de decisión. De todos modos (en el caso paralelo) la red neuronal no muestra una gran diferencia respecto al árbol, a diferencia del caso diagonal.

\newpage

\section{Ejercicio F}
Tuve dos ideas distintas para abordar este ejercicio. Ninguna de las dos dio buenos resultados para el dataset faces, pero voy a exponerlas igual.
\subsection{Usando una sola red neuronal}
\par Una primera idea que tuve fue, dado el input (.data .net y .test); modificar los archivos .data y .net para que en vez de tener un solo output, tuvieran $n$ donde $n$ es la cantidad de clases distintas del problema.
\par Escribí un programa en c que modifica los archivos .data y .net para, entonces, agregar una secuencia de ceros y unos reemplazando una linea como la siguiente:

\begin{verbatim} 0.45 1.34 -0.12 5 
\end{verbatim}

Donde el problema tiene clases 0,1,2,3,4,5 y 6 ; por la siguiente:

\begin{verbatim} 0.45 1.34 -0.12 0 0 0 0 0 1 0
\end{verbatim}

Luego, en el archivo .net se modifica la cantidad de neuronas en la capa de salida; se entrena la red neuronal modificada y se lee el .predic devuelto.

Para ese .predic, símplemente elegí como clase final de cada punto la clase correspondienete a la columna de mayor valor. 

Calcular el error discreto consistió en sumar las predicciones erradas y dividir por el total de elementos de test. 

Este enfoque, sin embargo, parece no ser bueno porque si bien para el dataset iris cometió 0\% de error; par el dataset faces los resultados eran del orden del 70\% de error.

El código se encuentra en la carpeta F1. Hay un archivo .txt explicando brevemente como está organizado.

\subsection{Usando muchas redes neuronales}

Otro intento consitió en, dados los inputs (por ejemplo iris.data, iris.net e iris.test) donde hay n (3) clases, crear un .data y un .net por cada clase.

El archivo iris.2.data  por ejemplo, contiene los mismos puntos pero cambian las clasificaciones: si el punto es de clase 2, entonces se le modifica la clase a 1. Si el punto es de clase distinta de 2, se le modifica a la clase a 0.

De este modo, entrené una red neuronal para cada clase de tal forma que cada red decidiera si un determinado punto está en una clase fija o no.

En base a esto, obtuve un archivo .predic por cada clase y clasifiqué a cada punto con la clase cuya predicción para ese punto fue mayor.

No sé si este enfoque es equivalente al anterior que mencioné, pero los resultados fueron casi iguales: para iris 0\% de error y para faces 70\% de error.

El código y predicciones se encuentran en la carpeta F2 y hay un .txt explicativo.

\subsection{¿Por qué no funcionan?}

Revisando ejemplos a mano pude ver que estas redes, en el dataset faces, por algún motivo devuelven a casi todos los puntos un valor constante. De ahí proviene el 70\%, por pararse en una clase particular y errarle con probabilidad $3/4$. No pude seguir intentando resolverlo porque ya es momento de entregar el trabajo.


\end{document}
